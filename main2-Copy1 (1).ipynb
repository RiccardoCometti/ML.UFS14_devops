{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (8.3.35)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (0.15.2+cu118)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from ultralytics) (2.0.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (3.25.0)\n",
      "Requirement already satisfied: lit in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (18.1.8)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (24.3.1)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (75.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lit in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (18.1.8)\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch==2.0.1+cu118 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision==0.15.2+cu118 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.15.2+cu118)\n",
      "Requirement already satisfied: torchaudio==2.0.2+cu118 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.0.2+cu118)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.1+cu118) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.1+cu118) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.1+cu118) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.1+cu118) (3.4)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.1+cu118) (3.1.4)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.1+cu118) (2.0.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision==0.15.2+cu118) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision==0.15.2+cu118) (2.32.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision==0.15.2+cu118) (11.0.0)\n",
      "Requirement already satisfied: cmake in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.25.0)\n",
      "Requirement already satisfied: lit in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1+cu118) (18.1.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch==2.0.1+cu118) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision==0.15.2+cu118) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision==0.15.2+cu118) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision==0.15.2+cu118) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision==0.15.2+cu118) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-build-isolation lit\n",
    "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "tensor([[-0.1425, -0.1149,  0.3991],\n",
      "        [-0.0072, -2.3335, -0.4276],\n",
      "        [-0.7205, -0.0649, -0.9123]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Usa 'cpu' se CUDA non Ã¨ disponibile\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Esempio: spostare un tensore sul dispositivo selezionato\n",
    "x = torch.randn(3, 3).to(device)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.35 ðŸš€ Python-3.10.15 torch-2.0.1+cu118 CPU (Intel Xeon E5-2686 v4 2.30GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/home/ec2-user/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 93.0MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/ec2-user/SageMaker/ML.UFS14_devops/train/labels... 1192 images, 210 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1192/1192 [00:01<00:00, 895.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/ec2-user/SageMaker/ML.UFS14_devops/train/labels.cache\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 756, len(boxes) = 1322. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/ec2-user/SageMaker/ML.UFS14_devops/valid/labels... 60 images, 8 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [00:00<00:00, 935.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/ec2-user/SageMaker/ML.UFS14_devops/valid/labels.cache\n",
      "WARNING âš ï¸ Box and segment counts should be equal, but got len(segments) = 44, len(boxes) = 79. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 13:41:06 INFO mlflow.tracking.fluent: Experiment with name '/Shared/Ultralytics' does not exist. Creating a new experiment.\n",
      "2024/11/21 13:41:06 WARNING mlflow.utils.autologging_utils: MLflow statsmodels autologging is known to be compatible with 0.11.1 <= statsmodels <= 0.14.3, but the installed version is 0.14.4. If you encounter errors during autologging, try upgrading / downgrading statsmodels to a compatible version, or try upgrading MLflow.\n",
      "2024/11/21 13:41:13 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n",
      "2024/11/21 13:41:13 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
      "2024/11/21 13:41:13 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(514ea909c243483fb623315dafabef9c) to runs/mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mview at http://127.0.0.1:5000 with 'mlflow server --backend-store-uri runs/mlflow'\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train3\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/20         0G      1.397      1.805      1.382         20        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:10<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.617      0.532      0.534      0.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/20         0G      1.484      1.403      1.442         17        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:08<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.501       0.47       0.46      0.241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/20         0G      1.501      1.383      1.451         22        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:08<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.396      0.418      0.298      0.123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/20         0G      1.478      1.312      1.426         18        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:09<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.706      0.517      0.535      0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/20         0G      1.474       1.34      1.429         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:08<00:00,  1.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.729      0.633      0.668      0.349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/20         0G      1.407      1.208      1.395         28        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:06<00:00,  1.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.684      0.696      0.685      0.335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/20         0G      1.364      1.204      1.376         12        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:06<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.707      0.611      0.688      0.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/20         0G      1.372       1.18      1.369         17        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:07<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.779      0.624      0.723      0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/20         0G      1.321      1.109      1.359         22        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:07<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.775      0.655      0.716      0.401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/20         0G      1.296      1.063      1.335         15        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:07<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.878      0.635      0.788      0.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/20         0G      1.173      1.014      1.275          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:07<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.861      0.628      0.761      0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/20         0G      1.121     0.9048      1.247          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:07<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.834      0.635      0.788      0.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/20         0G      1.106     0.8589      1.238          5        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:06<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.887      0.697      0.801      0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/20         0G       1.11     0.8218      1.234          7        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:07<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.784      0.759      0.806       0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/20         0G      1.067     0.7784        1.2          6        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:07<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.898      0.759      0.856      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/20         0G      1.009     0.7195      1.173         11        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:07<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.848      0.844      0.868      0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/20         0G     0.9958     0.7038      1.169          9        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:07<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.797      0.785      0.859      0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/20         0G     0.9704     0.6591      1.141         10        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:06<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.819      0.848      0.883      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/20         0G     0.9364     0.6362       1.13          8        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:07<00:00,  1.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.889      0.813      0.886      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/20         0G     0.9218     0.5943      1.126          7        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [01:07<00:00,  1.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.907      0.823      0.887      0.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "20 epochs completed in 0.388 hours.\n",
      "Optimizer stripped from runs/detect/train3/weights/last.pt, 6.2MB\n",
      "Optimizer stripped from runs/detect/train3/weights/best.pt, 6.2MB\n",
      "\n",
      "Validating runs/detect/train3/weights/best.pt...\n",
      "Ultralytics 8.3.35 ðŸš€ Python-3.10.15 torch-2.0.1+cu118 CPU (Intel Xeon E5-2686 v4 2.30GHz)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         60         79      0.905      0.823      0.887      0.546\n",
      "Speed: 0.2ms preprocess, 20.9ms inference, 0.0ms loss, 0.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to runs/mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7f3b6c9e2440>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.98182,     0.98182,     0.98182,     0.98182,\n",
       "            0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,\n",
       "            0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,\n",
       "            0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,\n",
       "            0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,\n",
       "            0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,\n",
       "            0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,\n",
       "            0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,\n",
       "            0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,\n",
       "            0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,\n",
       "            0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.98182,     0.96491,     0.96491,     0.96491,     0.96491,     0.96491,     0.96491,     0.96491,\n",
       "            0.96491,     0.96491,     0.96491,     0.96491,     0.96491,     0.96491,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,\n",
       "               0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,        0.95,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,\n",
       "            0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,\n",
       "            0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,\n",
       "            0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,\n",
       "            0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,\n",
       "            0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,\n",
       "            0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.77528,     0.77528,     0.77528,     0.77528,     0.77528,     0.77528,     0.77528,     0.77528,     0.77528,     0.77528,     0.77528,     0.77528,     0.77528,     0.68627,\n",
       "            0.68627,     0.68627,     0.68627,     0.68627,     0.68627,     0.68627,     0.68627,     0.68627,     0.68627,     0.68627,     0.68627,     0.68627,     0.66981,     0.66981,     0.66981,     0.66981,     0.66981,     0.66981,     0.66981,     0.66981,     0.66981,     0.66981,     0.66981,\n",
       "            0.66981,     0.36923,     0.36923,     0.36923,     0.36923,     0.36923,     0.36923,     0.36923,     0.36923,     0.36923,     0.36923,     0.36923,     0.36923,     0.36923,     0.24579,     0.24579,     0.24579,     0.24579,     0.24579,     0.24579,     0.24579,     0.24579,     0.24579,\n",
       "            0.24579,     0.24579,     0.24579,     0.24579,     0.18049,     0.18049,     0.18049,     0.18049,     0.18049,     0.18049,     0.18049,     0.18049,     0.18049,     0.18049,     0.18049,     0.18049,     0.14479,     0.14479,     0.14479,     0.14479,     0.14479,     0.14479,     0.14479,\n",
       "            0.14479,     0.14479,     0.14479,     0.14479,     0.14479,     0.14479,      0.1075,      0.1075,      0.1075,      0.1075,      0.1075,      0.1075,      0.1075,      0.1075,      0.1075,      0.1075,      0.1075,      0.1075,      0.1075,    0.092548,    0.092548,    0.092548,    0.092548,\n",
       "           0.092548,    0.092548,    0.092548,    0.092548,    0.092548,    0.092548,    0.092548,    0.092548,    0.050742,    0.048713,    0.046683,    0.044653,    0.042624,    0.040594,    0.038564,    0.036535,    0.034505,    0.032475,    0.030445,    0.028416,    0.026386,    0.024356,    0.022327,\n",
       "           0.020297,    0.018267,    0.016238,    0.014208,    0.012178,    0.010148,   0.0081188,   0.0060891,   0.0040594,   0.0020297,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.09753,    0.097576,     0.15064,     0.18022,     0.20646,     0.22719,     0.24583,     0.25478,      0.2743,     0.28914,     0.30207,     0.30923,     0.31939,     0.33028,     0.33577,     0.34379,     0.34989,     0.36012,     0.37212,     0.37748,     0.38612,     0.38894,      0.4044,\n",
       "            0.41676,     0.42519,     0.43018,      0.4385,     0.44816,     0.45541,     0.46787,      0.4739,     0.47717,     0.47899,     0.48322,     0.48857,     0.48993,     0.49817,     0.50965,     0.51299,     0.52213,     0.52528,     0.52494,     0.53253,     0.53629,     0.54115,     0.54388,\n",
       "            0.54744,     0.54905,      0.5499,     0.55125,     0.55842,      0.5674,     0.57017,     0.57986,     0.58406,     0.58963,     0.59258,     0.59536,      0.6008,     0.60647,      0.6107,     0.61493,     0.61568,     0.61643,     0.61718,     0.61843,     0.61988,     0.62731,     0.63042,\n",
       "            0.63976,      0.6439,     0.64937,      0.6509,     0.65653,     0.65968,     0.66234,     0.67004,     0.67241,     0.67774,     0.68363,     0.69152,     0.70062,      0.7068,     0.70897,     0.71108,     0.71314,     0.71525,     0.71727,      0.7183,     0.71933,     0.72036,     0.72284,\n",
       "            0.72676,     0.73445,     0.73628,     0.73704,      0.7378,     0.73856,     0.73932,     0.74434,     0.74594,     0.74764,     0.75033,     0.75542,     0.75605,     0.75667,      0.7573,     0.75792,     0.75854,     0.75916,     0.75987,     0.76062,     0.76137,     0.76212,     0.76286,\n",
       "            0.76366,     0.76463,      0.7656,     0.76657,     0.76753,     0.76193,     0.76408,     0.76543,     0.76613,     0.76684,     0.76755,     0.76825,     0.76896,     0.76965,     0.77033,     0.77102,      0.7717,     0.77238,     0.77306,     0.77278,     0.77097,     0.76917,     0.76735,\n",
       "            0.76882,     0.77534,      0.7764,     0.77746,     0.77852,     0.77958,     0.78965,     0.79249,     0.79595,     0.79843,     0.79986,     0.80129,     0.80708,     0.80733,     0.80759,     0.80784,     0.80809,     0.80834,      0.8086,     0.80885,      0.8091,     0.80935,      0.8096,\n",
       "            0.80985,     0.81011,     0.81036,     0.81061,     0.81086,     0.81111,     0.81136,     0.81161,     0.81289,     0.81572,     0.81766,      0.8192,     0.82075,     0.81458,     0.81513,     0.81568,     0.81622,     0.81677,     0.81732,     0.81787,     0.81841,     0.81896,     0.82031,\n",
       "             0.8228,     0.82513,     0.82724,     0.82945,     0.83436,     0.83489,     0.83542,     0.83595,     0.83648,     0.83701,     0.83754,     0.83807,     0.83859,     0.83912,     0.83964,     0.84013,     0.84063,     0.84112,     0.84162,     0.84211,      0.8426,     0.84309,     0.84359,\n",
       "            0.84408,     0.84457,     0.84498,     0.84536,     0.84573,     0.84611,     0.84649,     0.84686,     0.84724,     0.84761,     0.84799,     0.84836,     0.84874,     0.84911,     0.84948,     0.84986,     0.85326,      0.8608,     0.86094,     0.86108,     0.86123,     0.86137,     0.86151,\n",
       "            0.86165,     0.86179,     0.86193,     0.86207,     0.86221,     0.86235,     0.86249,     0.86263,     0.86277,     0.86291,     0.86305,     0.86319,     0.86333,     0.86347,     0.86361,     0.86375,     0.86389,     0.86403,     0.86417,      0.8643,     0.86444,     0.86458,     0.86472,\n",
       "            0.86486,       0.865,     0.86514,     0.86528,     0.86542,     0.86556,      0.8657,     0.86584,     0.86597,     0.86611,      0.8663,     0.86705,      0.8678,     0.86855,      0.8693,     0.87004,     0.87079,     0.87153,     0.87093,     0.86959,     0.86824,     0.86689,     0.86554,\n",
       "            0.86427,     0.86325,     0.86223,     0.86121,     0.86019,     0.85917,     0.85814,     0.85712,     0.85638,     0.85564,     0.85489,     0.85415,      0.8534,     0.85265,      0.8519,     0.85116,     0.85041,     0.84969,     0.85032,     0.85096,     0.85159,     0.85223,     0.85286,\n",
       "            0.85349,     0.85412,     0.85475,     0.85546,      0.8565,     0.85753,     0.85857,      0.8596,     0.86063,      0.8613,     0.86183,     0.86235,     0.86288,      0.8634,     0.86393,     0.86445,     0.86497,     0.86549,     0.86601,     0.86653,     0.86704,     0.86754,     0.86804,\n",
       "            0.86854,     0.86903,     0.86953,     0.87003,     0.87052,     0.87102,     0.87151,     0.87201,     0.87251,     0.87316,     0.87381,     0.87445,      0.8751,     0.87575,     0.87639,     0.87704,     0.87768,     0.87832,     0.87787,     0.87731,     0.87675,     0.87619,     0.87563,\n",
       "            0.87507,     0.87451,     0.87395,     0.87339,     0.87282,     0.87226,      0.8717,     0.87113,     0.87052,     0.86981,      0.8691,     0.86838,     0.86767,     0.86695,     0.86623,     0.86552,      0.8648,     0.86408,     0.86336,     0.86259,     0.86178,     0.86097,     0.86016,\n",
       "            0.85935,     0.85854,     0.85773,     0.85691,      0.8561,     0.85528,     0.85483,     0.85444,     0.85405,     0.85366,     0.85327,     0.85287,     0.85248,     0.85209,      0.8517,      0.8513,     0.85091,     0.85052,     0.85012,     0.84973,     0.84933,     0.84894,     0.84854,\n",
       "            0.84815,     0.84775,     0.84736,     0.84695,     0.84653,     0.84611,      0.8457,     0.84528,     0.84486,     0.84444,     0.84402,      0.8436,     0.84318,     0.84276,     0.84234,     0.84192,      0.8415,     0.84108,     0.84066,     0.84024,     0.83982,     0.83939,     0.83879,\n",
       "            0.83795,     0.83711,     0.83628,     0.83544,      0.8346,     0.83375,     0.83291,     0.83207,     0.83122,      0.8309,     0.83077,     0.83065,     0.83053,      0.8304,     0.83028,     0.83015,     0.83003,     0.82991,     0.82978,     0.82966,     0.82953,     0.82941,     0.82929,\n",
       "            0.82916,     0.82904,     0.82891,     0.82879,     0.82867,     0.82854,     0.82842,     0.82829,     0.82817,     0.82804,     0.82792,      0.8278,     0.82767,     0.82755,     0.82742,      0.8273,     0.82717,     0.82705,     0.82692,      0.8268,     0.82668,     0.82655,     0.82643,\n",
       "             0.8263,     0.82618,     0.82605,     0.82593,      0.8258,     0.82568,     0.82555,     0.82543,      0.8253,     0.82518,     0.82505,     0.82493,     0.82481,     0.82468,     0.82456,     0.82443,     0.82431,     0.82418,     0.82406,     0.82393,     0.82381,     0.82368,     0.82355,\n",
       "            0.82343,      0.8233,     0.82318,     0.82305,     0.82293,      0.8228,     0.82243,     0.82045,     0.81846,     0.81647,     0.81447,     0.81447,     0.81467,     0.81487,     0.81507,     0.81527,     0.81547,     0.81567,     0.81587,     0.81607,     0.81627,     0.81647,     0.81667,\n",
       "            0.81687,     0.81707,     0.81727,     0.81747,     0.81767,     0.81787,     0.81807,     0.81827,     0.81847,     0.81867,     0.81887,     0.81906,     0.81926,     0.81946,     0.81966,     0.81986,     0.82005,     0.82008,     0.81996,     0.81985,     0.81973,     0.81961,     0.81949,\n",
       "            0.81938,     0.81926,     0.81914,     0.81902,     0.81891,     0.81879,     0.81867,     0.81856,     0.81844,     0.81832,      0.8182,     0.81809,     0.81797,     0.81785,     0.81773,     0.81762,      0.8175,     0.81738,     0.81726,     0.81714,     0.81703,     0.81691,     0.81679,\n",
       "            0.81667,     0.81656,     0.81644,     0.81632,      0.8162,     0.81608,     0.81597,     0.81585,     0.81573,     0.81561,     0.81549,     0.81538,     0.81526,     0.81514,     0.81502,      0.8149,     0.81479,     0.81467,     0.81455,     0.81443,     0.81431,      0.8142,     0.81408,\n",
       "            0.81396,     0.81384,     0.81372,      0.8136,     0.81349,     0.81337,     0.81325,     0.81313,     0.81301,     0.81289,     0.81278,     0.81266,     0.81254,     0.81242,      0.8123,     0.81218,     0.81206,     0.81195,     0.81183,     0.81171,     0.81157,     0.81109,     0.81061,\n",
       "            0.81012,     0.80964,     0.80915,     0.80867,     0.80818,      0.8077,     0.80721,     0.80673,     0.80624,     0.80575,     0.80526,     0.80478,     0.80429,      0.8038,     0.80331,     0.80295,     0.80307,      0.8032,     0.80333,     0.80346,     0.80358,     0.80371,     0.80384,\n",
       "            0.80397,      0.8041,     0.80422,     0.80435,     0.80448,      0.8046,     0.80473,     0.80486,     0.80499,     0.80511,     0.80524,     0.80537,     0.80549,     0.80562,     0.80575,     0.80587,       0.806,     0.80613,     0.80625,     0.80638,     0.80651,     0.80663,     0.80676,\n",
       "            0.80689,     0.80701,     0.80714,     0.80726,     0.80739,     0.80752,     0.80764,     0.80777,     0.80789,     0.80802,     0.80815,     0.80827,      0.8084,     0.80852,     0.80865,     0.80877,     0.80864,     0.80834,     0.80804,     0.80774,     0.80744,     0.80714,     0.80683,\n",
       "            0.80653,     0.80623,     0.80593,     0.80563,     0.80532,     0.80502,     0.80472,     0.80442,     0.80412,     0.80381,     0.80351,     0.80321,      0.8029,      0.8026,      0.8023,     0.80199,     0.80169,     0.80138,     0.80108,     0.80078,     0.80047,     0.80017,      0.8005,\n",
       "             0.8016,      0.8027,      0.8038,     0.80488,     0.80597,     0.79868,      0.7957,     0.79402,     0.79234,     0.79065,     0.78896,      0.7878,     0.78757,     0.78734,     0.78711,     0.78688,     0.78665,     0.78642,     0.78619,     0.78596,     0.78574,     0.78551,     0.78528,\n",
       "            0.78505,     0.78482,     0.78459,     0.78436,     0.78413,      0.7839,     0.78367,     0.78344,     0.78321,     0.78298,     0.78275,     0.78252,     0.78229,     0.78206,     0.78183,      0.7816,     0.78136,     0.78113,      0.7809,     0.78067,     0.78044,     0.78021,     0.77998,\n",
       "            0.77975,     0.77951,     0.77928,     0.77905,     0.77882,     0.77853,     0.77798,     0.77742,     0.77686,     0.77631,     0.77575,     0.77519,     0.77463,     0.77407,     0.77351,     0.77295,     0.77239,     0.77183,     0.77126,      0.7707,     0.77014,     0.76957,     0.76861,\n",
       "            0.76702,     0.76543,     0.76383,     0.76223,     0.76063,     0.75778,     0.75316,     0.74948,     0.74787,     0.74625,     0.74462,       0.743,     0.74136,     0.73919,     0.73549,     0.73177,     0.72924,     0.72762,     0.72599,     0.72436,     0.72273,     0.72109,     0.71884,\n",
       "            0.71537,     0.71187,     0.70883,     0.70657,      0.7043,     0.70202,     0.69973,     0.69813,     0.69673,     0.69533,     0.69393,     0.69253,     0.69112,     0.68971,     0.68781,     0.68335,     0.67886,     0.67418,     0.66941,     0.65965,        0.65,     0.64171,     0.63164,\n",
       "            0.62815,     0.62465,     0.62113,      0.6217,     0.62284,     0.62397,      0.6251,     0.62568,     0.62209,     0.61849,     0.61487,      0.6127,     0.61096,     0.60922,     0.60748,     0.60573,     0.60397,     0.60221,     0.59275,      0.5795,     0.57569,     0.57456,     0.57342,\n",
       "            0.57229,     0.57115,     0.57002,     0.56888,     0.56773,     0.56659,     0.56545,      0.5643,     0.55929,     0.54994,     0.54641,     0.54286,     0.53929,     0.53586,     0.53267,     0.52947,     0.52626,     0.52284,     0.51776,     0.51263,     0.50829,     0.50527,     0.50223,\n",
       "            0.49919,     0.49613,     0.49111,     0.48527,     0.47638,      0.4592,     0.44622,     0.43588,     0.41914,     0.41301,     0.40684,     0.40231,     0.39914,     0.39596,     0.39277,     0.38957,     0.38675,     0.38442,     0.38209,     0.37975,     0.37741,     0.37506,      0.3727,\n",
       "            0.36977,     0.36575,     0.36171,     0.35764,     0.35325,     0.34706,     0.34083,     0.31116,     0.29655,     0.29106,     0.28553,     0.26214,     0.24433,     0.23918,     0.23401,      0.2288,     0.22206,     0.20988,     0.19844,     0.18754,     0.18055,     0.17552,     0.17045,\n",
       "            0.16536,     0.16048,     0.15583,     0.15115,     0.14645,     0.14172,     0.10516,    0.072031,     0.06861,    0.065177,    0.061732,    0.058275,    0.054805,    0.051322,    0.047541,    0.043387,    0.039215,    0.035025,    0.030817,    0.026591,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.051333,    0.051359,    0.081629,    0.099422,     0.11582,     0.12903,     0.14119,     0.14744,     0.16067,     0.17096,     0.18007,     0.18569,     0.19306,     0.20108,     0.20516,     0.21118,      0.2158,     0.22364,     0.23297,     0.23718,     0.24405,     0.24722,     0.25985,\n",
       "            0.27015,     0.27727,     0.28153,      0.2887,     0.29713,     0.30355,     0.31472,      0.3202,     0.32319,     0.32486,     0.32877,     0.33374,     0.33501,     0.34276,     0.35372,     0.35695,     0.36586,     0.36897,     0.37074,     0.37836,     0.38217,     0.38712,     0.38993,\n",
       "            0.39359,     0.39526,     0.39614,     0.39755,     0.40504,     0.41456,     0.41753,       0.428,      0.4326,     0.43873,     0.44201,     0.44512,     0.45122,     0.45764,     0.46248,     0.46735,     0.46822,     0.46908,     0.46995,     0.47141,     0.47309,      0.4818,     0.48548,\n",
       "            0.49665,     0.50166,     0.50833,     0.51021,     0.51716,     0.52108,     0.52441,     0.53413,     0.53715,     0.54397,      0.5516,     0.56195,     0.57407,     0.58242,     0.58537,     0.58826,     0.59108,     0.59399,     0.59677,      0.5982,     0.59963,     0.60106,     0.60452,\n",
       "            0.61003,     0.62094,     0.62357,     0.62466,     0.62575,     0.62685,     0.62794,     0.63522,     0.63755,     0.64004,     0.64399,     0.65153,     0.65246,     0.65339,     0.65432,     0.65525,     0.65618,     0.65711,     0.65818,      0.6593,     0.66043,     0.66155,     0.66268,\n",
       "            0.66388,     0.66535,     0.66682,     0.66829,     0.66975,     0.66829,     0.67162,     0.67369,     0.67479,     0.67589,     0.67699,     0.67809,     0.67918,     0.68026,     0.68134,     0.68241,     0.68348,     0.68455,     0.68562,     0.68595,     0.68513,     0.68431,     0.68348,\n",
       "            0.68659,     0.69707,     0.69879,     0.70051,     0.70223,     0.70395,     0.72055,     0.72529,      0.7311,      0.7353,     0.73773,     0.74016,     0.75011,     0.75054,     0.75098,     0.75142,     0.75186,     0.75229,     0.75273,     0.75317,      0.7536,     0.75404,     0.75448,\n",
       "            0.75492,     0.75535,     0.75579,     0.75623,     0.75667,      0.7571,     0.75754,     0.75798,      0.7602,     0.76518,     0.76859,     0.77133,     0.77407,      0.7731,     0.77409,     0.77508,     0.77607,     0.77706,     0.77805,     0.77904,     0.78004,     0.78103,     0.78349,\n",
       "            0.78805,     0.79233,     0.79624,     0.80035,     0.80954,     0.81054,     0.81154,     0.81254,     0.81354,     0.81454,     0.81554,     0.81654,     0.81754,     0.81854,     0.81953,     0.82047,     0.82142,     0.82236,     0.82331,     0.82425,      0.8252,     0.82614,     0.82708,\n",
       "            0.82803,     0.82897,     0.82977,      0.8305,     0.83123,     0.83195,     0.83268,     0.83341,     0.83414,     0.83486,     0.83559,     0.83632,     0.83705,     0.83777,      0.8385,     0.83923,     0.84589,     0.86085,     0.86113,     0.86141,     0.86169,     0.86197,     0.86225,\n",
       "            0.86254,     0.86282,      0.8631,     0.86338,     0.86366,     0.86394,     0.86422,      0.8645,     0.86479,     0.86507,     0.86535,     0.86563,     0.86591,     0.86619,     0.86647,     0.86675,     0.86704,     0.86732,      0.8676,     0.86788,     0.86816,     0.86844,     0.86872,\n",
       "              0.869,     0.86928,     0.86957,     0.86985,     0.87013,     0.87041,     0.87069,     0.87097,     0.87125,     0.87153,     0.87191,     0.87343,     0.87496,     0.87648,       0.878,     0.87953,     0.88105,     0.88257,     0.88293,     0.88265,     0.88236,     0.88208,     0.88179,\n",
       "            0.88153,     0.88131,     0.88109,     0.88087,     0.88065,     0.88043,     0.88021,        0.88,     0.87983,     0.87967,     0.87951,     0.87935,     0.87919,     0.87902,     0.87886,      0.8787,     0.87854,     0.87841,     0.87977,     0.88113,     0.88249,     0.88386,     0.88522,\n",
       "            0.88658,     0.88794,      0.8893,     0.89083,     0.89309,     0.89535,     0.89761,     0.89986,     0.90212,      0.9036,     0.90476,     0.90592,     0.90708,     0.90824,      0.9094,     0.91056,     0.91172,     0.91288,     0.91404,      0.9152,     0.91633,     0.91744,     0.91856,\n",
       "            0.91968,     0.92079,     0.92191,     0.92303,     0.92414,     0.92526,     0.92638,      0.9275,     0.92862,      0.9301,     0.93157,     0.93305,     0.93452,       0.936,     0.93747,     0.93895,     0.94042,      0.9419,     0.94197,     0.94191,     0.94185,     0.94178,     0.94172,\n",
       "            0.94166,      0.9416,     0.94153,     0.94147,     0.94141,     0.94134,     0.94128,     0.94122,     0.94115,     0.94107,     0.94099,     0.94091,     0.94083,     0.94074,     0.94066,     0.94058,      0.9405,     0.94042,     0.94034,     0.94025,     0.94016,     0.94006,     0.93997,\n",
       "            0.93987,     0.93978,     0.93969,     0.93959,      0.9395,     0.93941,     0.93935,     0.93931,     0.93926,     0.93922,     0.93917,     0.93912,     0.93908,     0.93903,     0.93898,     0.93894,     0.93889,     0.93885,      0.9388,     0.93875,     0.93871,     0.93866,     0.93862,\n",
       "            0.93857,     0.93852,     0.93848,     0.93843,     0.93838,     0.93833,     0.93828,     0.93823,     0.93818,     0.93813,     0.93808,     0.93803,     0.93798,     0.93793,     0.93788,     0.93783,     0.93778,     0.93773,     0.93768,     0.93763,     0.93758,     0.93753,     0.93745,\n",
       "            0.93735,     0.93725,     0.93715,     0.93705,     0.93694,     0.93684,     0.93674,     0.93664,     0.93654,      0.9365,     0.93648,     0.93647,     0.93645,     0.93644,     0.93642,      0.9364,     0.93639,     0.93637,     0.93636,     0.93634,     0.93633,     0.93631,      0.9363,\n",
       "            0.93628,     0.93627,     0.93625,     0.93624,     0.93622,      0.9362,     0.93619,     0.93617,     0.93616,     0.93614,     0.93613,     0.93611,      0.9361,     0.93608,     0.93607,     0.93605,     0.93604,     0.93602,       0.936,     0.93599,     0.93597,     0.93596,     0.93594,\n",
       "            0.93593,     0.93591,      0.9359,     0.93588,     0.93587,     0.93585,     0.93584,     0.93582,      0.9358,     0.93579,     0.93577,     0.93576,     0.93574,     0.93573,     0.93571,      0.9357,     0.93568,     0.93567,     0.93565,     0.93564,     0.93562,      0.9356,     0.93559,\n",
       "            0.93557,     0.93556,     0.93554,     0.93553,     0.93551,      0.9355,     0.93545,      0.9352,     0.93495,      0.9347,     0.93445,     0.93491,     0.93544,     0.93597,      0.9365,     0.93703,     0.93756,     0.93809,     0.93862,     0.93915,     0.93968,     0.94021,     0.94074,\n",
       "            0.94127,      0.9418,     0.94233,     0.94286,     0.94339,     0.94392,     0.94445,     0.94498,     0.94551,     0.94604,     0.94658,     0.94711,     0.94764,     0.94817,      0.9487,     0.94923,     0.94976,     0.94999,     0.94998,     0.94997,     0.94996,     0.94995,     0.94994,\n",
       "            0.94992,     0.94991,      0.9499,     0.94989,     0.94988,     0.94987,     0.94985,     0.94984,     0.94983,     0.94982,     0.94981,     0.94979,     0.94978,     0.94977,     0.94976,     0.94975,     0.94974,     0.94972,     0.94971,      0.9497,     0.94969,     0.94968,     0.94967,\n",
       "            0.94965,     0.94964,     0.94963,     0.94962,     0.94961,      0.9496,     0.94958,     0.94957,     0.94956,     0.94955,     0.94954,     0.94953,     0.94951,      0.9495,     0.94949,     0.94948,     0.94947,     0.94946,     0.94944,     0.94943,     0.94942,     0.94941,      0.9494,\n",
       "            0.94939,     0.94937,     0.94936,     0.94935,     0.94934,     0.94933,     0.94932,      0.9493,     0.94929,     0.94928,     0.94927,     0.94926,     0.94925,     0.94923,     0.94922,     0.94921,      0.9492,     0.94919,     0.94918,     0.94916,     0.94915,      0.9491,     0.94905,\n",
       "              0.949,     0.94895,      0.9489,     0.94886,     0.94881,     0.94876,     0.94871,     0.94866,     0.94861,     0.94856,     0.94851,     0.94846,     0.94841,     0.94836,     0.94832,     0.94835,      0.9487,     0.94906,     0.94942,     0.94978,     0.95013,     0.95049,     0.95085,\n",
       "             0.9512,     0.95156,     0.95192,     0.95228,     0.95263,     0.95299,     0.95335,      0.9537,     0.95406,     0.95442,     0.95477,     0.95513,     0.95549,     0.95585,      0.9562,     0.95656,     0.95692,     0.95727,     0.95763,     0.95799,     0.95835,      0.9587,     0.95906,\n",
       "            0.95942,     0.95977,     0.96013,     0.96049,     0.96084,      0.9612,     0.96156,     0.96192,     0.96227,     0.96263,     0.96299,     0.96334,      0.9637,     0.96406,     0.96442,     0.96477,      0.9649,     0.96488,     0.96486,     0.96483,     0.96481,     0.96479,     0.96477,\n",
       "            0.96475,     0.96473,     0.96471,     0.96468,     0.96466,     0.96464,     0.96462,      0.9646,     0.96458,     0.96456,     0.96453,     0.96451,     0.96449,     0.96447,     0.96445,     0.96443,      0.9644,     0.96438,     0.96436,     0.96434,     0.96432,      0.9643,     0.96574,\n",
       "            0.96896,     0.97217,     0.97539,      0.9786,     0.98182,     0.98154,     0.98143,     0.98137,      0.9813,     0.98124,     0.98117,     0.98113,     0.98112,     0.98111,      0.9811,     0.98109,     0.98108,     0.98107,     0.98107,     0.98106,     0.98105,     0.98104,     0.98103,\n",
       "            0.98102,     0.98101,       0.981,     0.98099,     0.98098,     0.98098,     0.98097,     0.98096,     0.98095,     0.98094,     0.98093,     0.98092,     0.98091,      0.9809,     0.98089,     0.98089,     0.98088,     0.98087,     0.98086,     0.98085,     0.98084,     0.98083,     0.98082,\n",
       "            0.98081,      0.9808,     0.98079,     0.98079,     0.98078,     0.98077,     0.98074,     0.98072,      0.9807,     0.98068,     0.98065,     0.98063,     0.98061,     0.98059,     0.98056,     0.98054,     0.98052,      0.9805,     0.98047,     0.98045,     0.98043,     0.98041,     0.98037,\n",
       "             0.9803,     0.98024,     0.98017,      0.9801,     0.98004,     0.97992,     0.97972,     0.97957,      0.9795,     0.97943,     0.97936,     0.97929,     0.97922,     0.97912,     0.97896,     0.97879,     0.97868,     0.97861,     0.97853,     0.97846,     0.97838,     0.97831,     0.97821,\n",
       "            0.97804,     0.97788,     0.97774,     0.97763,     0.97752,     0.97741,      0.9773,     0.97722,     0.97715,     0.97708,     0.97701,     0.97694,     0.97687,      0.9768,     0.97671,     0.97648,     0.97625,       0.976,     0.97575,     0.97523,     0.97469,     0.97422,     0.97363,\n",
       "            0.97342,     0.97321,       0.973,     0.97795,     0.98362,      0.9893,     0.99498,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n",
       "                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.97468,     0.97468,     0.97468,     0.96203,     0.94937,     0.94937,     0.94937,     0.93671,     0.93671,     0.93671,     0.93671,     0.92405,     0.92405,     0.92405,     0.92405,     0.92405,     0.92405,     0.92405,     0.92405,     0.92405,     0.92405,     0.91139,     0.91139,\n",
       "            0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.91139,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,\n",
       "            0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,\n",
       "            0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,\n",
       "            0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.89873,\n",
       "            0.89873,     0.89873,     0.89873,     0.89873,     0.89873,     0.88608,     0.88608,     0.88608,     0.88608,     0.88608,     0.88608,     0.88608,     0.88608,     0.88608,     0.88608,     0.88608,     0.88608,     0.88608,     0.88608,     0.88477,     0.88141,     0.87805,     0.87469,\n",
       "            0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,\n",
       "            0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.87342,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,\n",
       "            0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,\n",
       "            0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,\n",
       "            0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,\n",
       "            0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.86076,     0.85925,     0.85691,     0.85456,     0.85222,     0.84988,\n",
       "            0.84768,     0.84592,     0.84417,     0.84241,     0.84066,     0.83891,     0.83715,     0.83541,     0.83414,     0.83288,     0.83161,     0.83035,     0.82908,     0.82782,     0.82655,     0.82529,     0.82402,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,\n",
       "            0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,\n",
       "            0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82278,     0.82194,       0.821,     0.82007,     0.81914,     0.81821,\n",
       "            0.81728,     0.81635,     0.81542,     0.81449,     0.81356,     0.81262,     0.81169,     0.81076,     0.80975,     0.80858,     0.80741,     0.80624,     0.80506,     0.80389,     0.80272,     0.80155,     0.80037,      0.7992,     0.79803,     0.79678,     0.79547,     0.79416,     0.79285,\n",
       "            0.79154,     0.79023,     0.78892,      0.7876,     0.78629,     0.78498,     0.78427,     0.78364,     0.78301,     0.78239,     0.78176,     0.78113,     0.78051,     0.77988,     0.77926,     0.77863,       0.778,     0.77738,     0.77675,     0.77613,      0.7755,     0.77487,     0.77425,\n",
       "            0.77362,     0.77299,     0.77237,     0.77172,     0.77106,      0.7704,     0.76974,     0.76908,     0.76843,     0.76777,     0.76711,     0.76645,     0.76579,     0.76513,     0.76447,     0.76381,     0.76315,     0.76249,     0.76183,     0.76118,     0.76052,     0.75986,     0.75891,\n",
       "            0.75761,     0.75631,     0.75501,     0.75371,     0.75241,      0.7511,      0.7498,      0.7485,      0.7472,      0.7467,     0.74651,     0.74632,     0.74613,     0.74594,     0.74575,     0.74556,     0.74537,     0.74518,     0.74499,      0.7448,     0.74461,     0.74442,     0.74423,\n",
       "            0.74404,     0.74385,     0.74366,     0.74347,     0.74328,     0.74309,      0.7429,     0.74271,     0.74252,     0.74233,     0.74214,     0.74195,     0.74176,     0.74157,     0.74138,     0.74119,       0.741,     0.74081,     0.74062,     0.74043,     0.74024,     0.74005,     0.73985,\n",
       "            0.73966,     0.73947,     0.73928,     0.73909,      0.7389,     0.73871,     0.73852,     0.73833,     0.73814,     0.73795,     0.73776,     0.73757,     0.73738,     0.73719,       0.737,     0.73681,     0.73662,     0.73643,     0.73624,     0.73605,     0.73586,     0.73567,     0.73548,\n",
       "            0.73529,      0.7351,     0.73491,     0.73472,     0.73453,     0.73434,     0.73378,     0.73078,     0.72779,     0.72479,      0.7218,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,\n",
       "            0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72152,     0.72142,     0.72125,     0.72108,      0.7209,     0.72073,     0.72055,\n",
       "            0.72038,      0.7202,     0.72003,     0.71985,     0.71968,      0.7195,     0.71933,     0.71915,     0.71898,     0.71881,     0.71863,     0.71846,     0.71828,     0.71811,     0.71793,     0.71776,     0.71758,     0.71741,     0.71723,     0.71706,     0.71688,     0.71671,     0.71654,\n",
       "            0.71636,     0.71619,     0.71601,     0.71584,     0.71566,     0.71549,     0.71531,     0.71514,     0.71496,     0.71479,     0.71461,     0.71444,     0.71427,     0.71409,     0.71392,     0.71374,     0.71357,     0.71339,     0.71322,     0.71304,     0.71287,     0.71269,     0.71252,\n",
       "            0.71235,     0.71217,       0.712,     0.71182,     0.71165,     0.71147,      0.7113,     0.71112,     0.71095,     0.71077,      0.7106,     0.71042,     0.71025,     0.71008,      0.7099,     0.70973,     0.70955,     0.70938,      0.7092,     0.70903,     0.70883,     0.70812,     0.70741,\n",
       "             0.7067,     0.70599,     0.70528,     0.70457,     0.70386,     0.70315,     0.70244,     0.70174,     0.70103,     0.70032,     0.69961,      0.6989,     0.69819,     0.69748,     0.69677,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,\n",
       "             0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,\n",
       "             0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,      0.6962,     0.69594,      0.6955,     0.69507,     0.69464,      0.6942,     0.69377,     0.69333,\n",
       "             0.6929,     0.69246,     0.69203,      0.6916,     0.69116,     0.69073,     0.69029,     0.68986,     0.68943,     0.68899,     0.68856,     0.68812,     0.68769,     0.68725,     0.68682,     0.68639,     0.68595,     0.68552,     0.68508,     0.68465,     0.68422,     0.68378,     0.68354,\n",
       "            0.68354,     0.68354,     0.68354,     0.68354,     0.68354,     0.67326,     0.66908,     0.66674,      0.6644,     0.66206,     0.65972,     0.65811,      0.6578,     0.65748,     0.65717,     0.65685,     0.65654,     0.65622,     0.65591,     0.65559,     0.65528,     0.65496,     0.65465,\n",
       "            0.65433,     0.65402,      0.6537,     0.65339,     0.65308,     0.65276,     0.65245,     0.65213,     0.65182,      0.6515,     0.65119,     0.65087,     0.65056,     0.65024,     0.64993,     0.64961,      0.6493,     0.64898,     0.64867,     0.64835,     0.64804,     0.64772,     0.64741,\n",
       "            0.64709,     0.64678,     0.64646,     0.64615,     0.64583,     0.64544,     0.64469,     0.64394,     0.64318,     0.64243,     0.64167,     0.64092,     0.64016,     0.63941,     0.63865,      0.6379,     0.63714,     0.63639,     0.63563,     0.63488,     0.63413,     0.63337,     0.63208,\n",
       "            0.62996,     0.62785,     0.62573,     0.62361,     0.62149,     0.61774,      0.6117,     0.60693,     0.60484,     0.60275,     0.60066,     0.59857,     0.59648,      0.5937,     0.58901,     0.58431,     0.58112,     0.57909,     0.57706,     0.57503,       0.573,     0.57097,     0.56819,\n",
       "            0.56391,     0.55964,     0.55594,     0.55319,     0.55045,      0.5477,     0.54496,     0.54303,     0.54137,      0.5397,     0.53804,     0.53637,     0.53471,     0.53304,      0.5308,     0.52557,     0.52035,     0.51494,     0.50946,     0.49837,     0.48758,     0.47842,     0.46745,\n",
       "            0.46369,     0.45993,     0.45616,      0.4557,      0.4557,      0.4557,      0.4557,     0.45526,     0.45147,     0.44769,      0.4439,     0.44165,     0.43985,     0.43804,     0.43624,     0.43444,     0.43263,     0.43083,     0.42121,     0.40796,     0.40419,     0.40307,     0.40196,\n",
       "            0.40084,     0.39973,     0.39862,      0.3975,     0.39639,     0.39527,     0.39416,     0.39305,     0.38821,     0.37926,      0.3759,     0.37255,      0.3692,     0.36599,     0.36302,     0.36006,     0.35709,     0.35395,     0.34931,     0.34466,     0.34074,     0.33803,     0.33532,\n",
       "            0.33261,      0.3299,     0.32548,     0.32036,     0.31267,     0.29803,     0.28718,     0.27868,     0.26513,     0.26025,     0.25537,     0.25181,     0.24933,     0.24686,     0.24438,      0.2419,     0.23973,     0.23795,     0.23616,     0.23438,     0.23259,     0.23081,     0.22903,\n",
       "            0.22682,      0.2238,     0.22078,     0.21776,     0.21451,     0.20997,     0.20542,     0.18425,     0.17409,     0.17032,     0.16654,     0.15084,     0.13916,     0.13584,     0.13251,     0.12918,      0.1249,     0.11725,     0.11015,     0.10347,    0.099235,      0.0962,    0.093165,\n",
       "            0.09013,     0.08724,    0.084496,    0.081753,     0.07901,    0.076266,    0.055498,    0.037361,    0.035524,    0.033686,    0.031849,    0.030012,    0.028174,    0.026337,     0.02435,    0.022175,        0.02,    0.017825,     0.01565,    0.013475,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
       "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.5803988011255544\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.54638])\n",
       "names: {0: 'car'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9047608384676005, 'metrics/recall(B)': 0.8227848101265823, 'metrics/mAP50(B)': 0.8865875381820074, 'metrics/mAP50-95(B)': 0.5463778303415041, 'fitness': 0.5803988011255544}\n",
       "save_dir: PosixPath('runs/detect/train3')\n",
       "speed: {'preprocess': 0.19206603368123373, 'inference': 20.890164375305176, 'loss': 0.00012715657552083334, 'postprocess': 0.3574848175048828}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(data=\"data.yaml\", task=\"detect\", epochs=20, imgsz=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#risultato = model(source=\"C:/Users/RiccardoCometti/OneDrive - ITS Angelo Rizzoli/Deep Learning/progetto_deep2/vehicle detection.v3i.yolov8/nuovo_test13.jpg\", show=True, conf=0.4, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save('modello addestrato')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello salvato su S3: s3://nuovobucketdevops/modelli/modello addestrato\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'nuovobucketdevops'\n",
    "s3.upload_file('modello addestrato', bucket_name, 'modelli/modello addestrato')\n",
    "\n",
    "print(f\"Modello salvato su S3: s3://{bucket_name}/modelli/modello addestrato\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# Definisci il modello SageMaker\n",
    "#pytorch_model = PyTorchModel(\n",
    "   # model_data=f's3://{bucket_name}/modelli/modello addestrato.pth',\n",
    "   # role='IAM_ROLE',\n",
    "   # entry_point='inference.py',  # Script per gestire le richieste\n",
    "   # framework_version='1.12',\n",
    "   # py_version='py38',\n",
    "#)\n",
    "\n",
    "# Crea l'endpoint\n",
    "#predictor = pytorch_model.deploy(instance_type='ml.m5.large', initial_instance_count=1)\n",
    "\n",
    "# Usa l'endpoint per l'inferenza\n",
    "#response = predictor.predict(data)\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Salva i pesi del modello in formato state_dict\n",
    "torch.save(model.state_dict(), 'modello addestrato')\n",
    "\n",
    "# Comprimi il file in un formato .tar.gz richiesto da SageMaker\n",
    "import tarfile\n",
    "with tarfile.open('modello addestrato.tar.gz', 'w:gz') as tar:\n",
    "    tar.add('modello addestrato')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# Percorso del modello in S3\n",
    "s3_model_path = 's3://nuovobucketdevops/ML.UFS14_devops/modellotorch.tar.gz'\n",
    "\n",
    "# Configurazione del modello\n",
    "role = 'c133245a3375001l7613522t1w13-SageMakerExecutionRole-CP42wdk49gq0'  # Assicurati che abbia i permessi per usare SageMaker e S3\n",
    "model = PyTorchModel(\n",
    "    model_data=s3_model_path,\n",
    "    role=role,\n",
    "    entry_point='inference.py',  # Script per l'inferenza\n",
    "    framework_version='1.10.0',  # Versione di PyTorch\n",
    "    py_version='py38'  # Versione di Python\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (59.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorflow) (3.12.1)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (13.9.3)\n",
      "Requirement already satisfied: namex in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading grpcio-1.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, opt-einsum, ml-dtypes, grpcio, gast, astunparse, tensorboard, tensorflow\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml_dtypes 0.5.0\n",
      "    Uninstalling ml_dtypes-0.5.0:\n",
      "      Successfully uninstalled ml_dtypes-0.5.0\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 grpcio-1.68.0 libclang-18.1.1 ml-dtypes-0.4.1 opt-einsum-3.4.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==3.5.0\n",
      "  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: absl-py in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras==3.5.0) (2.1.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras==3.5.0) (1.26.4)\n",
      "Requirement already satisfied: rich in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras==3.5.0) (13.9.3)\n",
      "Requirement already satisfied: namex in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras==3.5.0) (0.0.8)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras==3.5.0) (3.12.1)\n",
      "Requirement already satisfied: optree in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras==3.5.0) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras==3.5.0) (0.4.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from keras==3.5.0) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from optree->keras==3.5.0) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging->keras==3.5.0) (3.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich->keras==3.5.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich->keras==3.5.0) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras==3.5.0) (0.1.2)\n",
      "Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 3.6.0\n",
      "    Uninstalling keras-3.6.0:\n",
      "      Successfully uninstalled keras-3.6.0\n",
      "Successfully installed keras-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==3.5.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import glob\n",
    "import sys\n",
    "from os import environ\n",
    "from flask import Flask\n",
    "from keras import models\n",
    "import numpy as np\n",
    "from flask import request\n",
    "import torch\n",
    "\n",
    "\n",
    "logging.debug('Init a Flask app')\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "def doit(param1, param2, param3):\n",
    "    # Prepara il modello\n",
    "    model_dir = environ['ML.UFS14_devops']\n",
    "    model = torch.load(f\"{model_dir}/modellotorch.pt\")\n",
    "    model.eval()\n",
    "\n",
    "    # Prepara i dati di input\n",
    "    predict_input = torch.tensor([[param1, param2, param3]], dtype=torch.float32)\n",
    "\n",
    "    # Inferenza\n",
    "    with torch.no_grad():\n",
    "        predict_result = model(predict_input).numpy()\n",
    "\n",
    "    # Restituisci i risultati come JSON\n",
    "    return json.dumps({\n",
    "        \"inputs\": predict_input.tolist(),\n",
    "        \"predict_result\": predict_result.tolist()\n",
    "    })\n",
    "\n",
    "@app.route('/invocations', methods=['POST'])\n",
    "def invocations():\n",
    "    http_request_post_payload = request.json\n",
    "\n",
    "    # Estrai piÃ¹ parametri\n",
    "    param1 = float(http_request_post_payload['param1'])\n",
    "    param2 = float(http_request_post_payload['param2'])\n",
    "    param3 = float(http_request_post_payload['param3'])\n",
    "\n",
    "    return doit(param1, param2, param3)\n",
    "\n",
    "    return json.dumps({\n",
    "    \"status\": \"success\",\n",
    "    \"model_name\": \"modellotorch\",\n",
    "    \"inputs\": predict_input.tolist(),\n",
    "    \"predict_result\": predict_result.tolist(),\n",
    "    \"execution_time_ms\": 123  # Calcola questo valore se necessario\n",
    "    })    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
